{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb8e4b9c-727f-4745-8e93-2d6f24004993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import scipy.linalg as la\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e96654d-9739-4744-a52e-5d23c2f0dd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "policies = [\"r_star\", \"mw\", \"dpp\", \"wi\", \"mwa\", \"wp\", \"ld\"]\n",
    "policy = policies[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42a798c8-b669-4d17-9916-ef62fa24afff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate M random walk traces of length K bounded in (0,1]\n",
    "\n",
    "Inputs: \n",
    "M : number of traces\n",
    "K : length of trace\n",
    "p_init_i: vector of initial p values for each trace (M x 1)\n",
    "volatility_param: Average step size at each time slot\n",
    "bernoulli_param: Tradeoff between frequency of changes and step size for positive and negative steps\n",
    "\n",
    "Outputs:\n",
    "p_i_k : Matrix of probability traces (M x K)\n",
    "\"\"\"\n",
    "def generate_prob_traces(M, K, p_init_i, random_state, volatility_param, bernoulli_param=0.5, max_deviation_param = 0.25):\n",
    "    # Each Bernoulli RV is mean-shited so that its expected value is zero\n",
    "    bernoulli_rvs = volatility_param*(stats.bernoulli(p=bernoulli_param).rvs((M, K-1), random_state=random_state)-bernoulli_param)\n",
    "    \n",
    "    p_i_k = np.zeros((M, K))\n",
    "    p_i_k[:, 0] = p_init_i\n",
    "    for slot in range(K-1):\n",
    "        p_i_k[:, slot+1] = p_i_k[:, slot] + bernoulli_rvs[:, slot]\n",
    "    \n",
    "        # Enforce upper and lower bounds\n",
    "        upper_bound = np.where(p_i + max_deviation_param > 1, 1, p_i + max_deviation_param)\n",
    "        lower_bound = np.where(p_i - max_deviation_param < volatility_param, volatility_param, p_i - max_deviation_param) # smallest value above zero\n",
    "        p_i_k[:, slot+1] = np.where(p_i_k[:, slot+1] > upper_bound, upper_bound, p_i_k[:, slot+1])\n",
    "        p_i_k[:, slot+1] = np.where(p_i_k[:, slot+1] < lower_bound, lower_bound, p_i_k[:, slot+1])\n",
    "\n",
    "    return p_i_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73c71bcb-d3be-4a2e-8bfa-b9e87d32abb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Simulate the optimal stationary randomized policy\n",
    "\n",
    "Inputs:\n",
    "M : number of nodes\n",
    "K : time horizon\n",
    "alpha_i : per-node weight (M x 1)\n",
    "q_i : per-node throughput constraint (M x 1)\n",
    "p_i_k : per-node probability trace (M x K)\n",
    "p_est_init_i : per-node initial probability estimate (M x 1)\n",
    "G : number of simulations (output will be averaged over G)\n",
    "K_opt : optimization horizon (how often the optimization is performed)\n",
    "zeta : exponential moving average estimator weight\n",
    "\n",
    "Outputs:\n",
    "J_avg_exp : expected weighted sum AoI\n",
    "x_max_norm : max normalized throughput debt\n",
    "p_i_est_avg : per-node estimated probability trace (M x K)\n",
    "\"\"\"\n",
    "\n",
    "def sim_opt_stat_random_policy(M, K, alpha_i, q_i, p_i_k, p_est_init_i, G, K_opt, zeta, exact=False):\n",
    "    J_avg_exp = 0\n",
    "    x_max_norm = 0\n",
    "    p_i_est_avg = np.zeros((M,K))\n",
    "\n",
    "    # Repeat simulation over G samples\n",
    "    for z in range(G):\n",
    "        # Initialize transmission matrix\n",
    "        d_i_k = np.zeros((M,K))\n",
    "    \n",
    "        # Initialize AoI and throughput debt vectors\n",
    "        h_i = np.ones(M)\n",
    "        x_i = np.zeros(M)\n",
    "    \n",
    "        # Generate outcome matrix that indicate whether transmission is successful in each time slot, assuming it is the selected time slot\n",
    "        o_i_k = stats.bernoulli.rvs(p=p_i_k, size=(M,K), random_state=z+1000)\n",
    "\n",
    "        # DEBUG:\n",
    "        #J_avg_g = 0\n",
    "    \n",
    "        # Initialize estimates of p_i\n",
    "        p_i_est = np.copy(p_est_init_i)\n",
    "    \n",
    "        # For each optimization horizon\n",
    "        for opt_hor in range(int(K/K_opt)):\n",
    "            # Throughput requirements for optimization\n",
    "            tp_sum = np.sum(q_i/p_i_est)\n",
    "            \n",
    "            # Check whether q is a feasible set of minimum throughput requirements\n",
    "            q_i_opt = q_i\n",
    "            if tp_sum > 1.0:\n",
    "                # Best we can do is solve the optimization problem with lower throughput requirements\n",
    "                q_i_opt /= tp_sum\n",
    "                #print(f\"R* : TP Req Unfeasible {tp_sum}, opt no {opt_hor+1}\")\n",
    "\n",
    "            # Repeated calculation\n",
    "            q_i_div_p_i = q_i_opt/p_i_est\n",
    "            \n",
    "            # Solve optimization\n",
    "            gamma_i = alpha_i*p_i_est/(M*q_i_opt**2)\n",
    "            gamma = gamma_test = np.max(gamma_i)\n",
    "            sqrt = np.sqrt(gamma_i/gamma_test)\n",
    "            mu_i = mu_i_test = q_i_div_p_i * np.where(sqrt > 1, sqrt, 1)\n",
    "            S = S_test = np.sum(mu_i_test)\n",
    "    \n",
    "            # Get close to the optimal value through successive division by 2 (This significantly speeds up optimization)\n",
    "            while S_test < 1.0:\n",
    "                gamma = gamma_test\n",
    "                mu_i = mu_i_test\n",
    "                S = S_test\n",
    "                \n",
    "                gamma_test /= 2.0\n",
    "                sqrt = np.sqrt(gamma_i/gamma_test)\n",
    "                mu_i_test = q_i_div_p_i * np.where(sqrt > 1, sqrt, 1)\n",
    "                S_test = np.sum(mu_i_test)\n",
    "\n",
    "            # More exact optimization starting from value from previous loop\n",
    "            step_size = 0.1\n",
    "            while S < 1.0:\n",
    "                S_prev = S\n",
    "                gamma -= step_size\n",
    "                sqrt = np.sqrt(gamma_i/gamma)\n",
    "                mu_i = q_i_div_p_i * np.where(sqrt > 1, sqrt, 1)\n",
    "                S = np.sum(mu_i)\n",
    "\n",
    "                # Adjust step size dynamically if it is too small\n",
    "                if np.abs(S-S_prev) < 0.001:\n",
    "                    step_size *= 2\n",
    "    \n",
    "            # Ensure that mu_i exactly add up to one\n",
    "            mu_i /= la.norm(mu_i, ord=1)\n",
    "            \n",
    "            # Sample to determine which nodes will be scheduled in which slot (for all the slots in the opt horizon)\n",
    "            i_k = stats.rv_discrete(a=1, b=M, values=(i, mu_i)).rvs(size=K_opt, random_state=888*z+opt_hor)\n",
    "    \n",
    "            # Loop over slots\n",
    "            for k in range(K_opt):\n",
    "                # Calculate transmission matrix that indiciates which node has an arrival in this slot\n",
    "                i_sel_idx = i_k[k]-1\n",
    "                arrival_successful = o_i_k[i_sel_idx, k + opt_hor*K_opt]\n",
    "                d_i_k[i_sel_idx, k + opt_hor*K_opt] = arrival_successful\n",
    "    \n",
    "                # Calculate weighted sum AoI\n",
    "                J_avg_exp += np.sum(alpha_i * h_i)\n",
    "                \n",
    "                # Update AoI and throughput debt vectors\n",
    "                h_i += 1\n",
    "                if arrival_successful: # if transmission was successful\n",
    "                    h_i[i_sel_idx] = 1\n",
    "                x_i += q_i - d_i_k[:, k + opt_hor*K_opt]\n",
    "    \n",
    "                # Update estimate for the scheduled node\n",
    "                if exact:\n",
    "                    p_i_est = p_i_k[:, k + opt_hor*K_opt]\n",
    "                else:\n",
    "                    p_i_est[i_sel_idx] = zeta*arrival_successful + (1-zeta)*p_i_est[i_sel_idx]\n",
    "                p_i_est_avg[:, k + opt_hor*K_opt] += p_i_est\n",
    "    \n",
    "        # Calculate max normalized throughput debt\n",
    "        x_max_norm += np.max(np.where(x_i > 0, x_i, 0) / (K*q_i))\n",
    "    \n",
    "    J_avg_exp /= (G*K*M)\n",
    "    x_max_norm /= G\n",
    "    p_i_est_avg /= G\n",
    "\n",
    "    return J_avg_exp, x_max_norm, p_i_est_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72471b33-3201-4057-8b5b-832d864e642d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Simulate the max-weight policy\n",
    "\n",
    "Inputs:\n",
    "M : number of nodes\n",
    "K : time horizon\n",
    "alpha_i : per-node weight (M x 1)\n",
    "q_i : per-node throughput constraint (M x 1)\n",
    "p_i_k : per-node probability trace (M x K)\n",
    "p_est_init_i : per-source initial probability estimate (M x 1)\n",
    "V : priority of throughput constraint in scheduling\n",
    "G : number of simulations (output will be averaged over G)\n",
    "zeta : exponential moving average estimator weight\n",
    "\n",
    "Outputs:\n",
    "J_avg_exp : expected weighted sum AoI\n",
    "x_max_norm : max normalized throughput debt\n",
    "p_i_est_avg : per-node estimated probability trace (M x K)\n",
    "\"\"\"\n",
    "\n",
    "def sim_max_weight_policy(M, K, alpha_i, q_i, p_i_k, p_est_init_i, V, G, zeta, exact=False):\n",
    "    J_avg_exp = 0\n",
    "    x_max_norm = 0\n",
    "    p_i_est_avg = np.zeros((M,K))\n",
    "    \n",
    "    # Repeat simulation\n",
    "    for z in range(G):\n",
    "        # Initialize transmission matrix that indiciates which node has an arrival in which slot\n",
    "        d_i_k = np.zeros((M,K))\n",
    "        \n",
    "        # Initialize AoI and throughput debt vectors\n",
    "        h_i = np.ones(M)\n",
    "        x_i = np.zeros(M)\n",
    "    \n",
    "        # Generate outcome matrix that indicates whether transmission is successful in each time slot, assuming it is the selected time slot\n",
    "        o_i_k = stats.bernoulli.rvs(p=p_i_k, size=(M,K), random_state=z+2000)\n",
    "\n",
    "        # DEBUG:\n",
    "        #J_avg_g = 0\n",
    "    \n",
    "        # Initialize estimates of p_i\n",
    "        p_i_est = np.copy(p_est_init_i)\n",
    "        \n",
    "        # Loop over slots\n",
    "        for k in range(K):\n",
    "            # Select node according to policy\n",
    "            W_i = (0.5*alpha_i*(h_i**2+2*h_i) + V*np.where(x_i > 0, x_i, 0))*p_i_est\n",
    "            i_sel_idx = np.argmax(W_i)\n",
    "            \n",
    "            # Update transmission matrix based on whether transmission was successful or not\n",
    "            arrival_successful = o_i_k[i_sel_idx, k]\n",
    "            d_i_k[i_sel_idx, k] = arrival_successful\n",
    "    \n",
    "            # Calculate weighted sum AoI\n",
    "            J_avg_exp += np.sum(alpha_i * h_i)\n",
    "            #J_avg_g += np.sum(alpha_i * h_i)\n",
    "            \n",
    "            # Update AoI and throughput debt vectors\n",
    "            h_i += 1\n",
    "            if arrival_successful: # if transmission was successful\n",
    "                h_i[i_sel_idx] = 1\n",
    "            x_i += q_i - d_i_k[:, k]\n",
    "    \n",
    "            # Update estimate for the scheduled node\n",
    "            if exact:\n",
    "                p_i_est = p_i_k[:, k]\n",
    "            else:\n",
    "                p_i_est[i_sel_idx] = zeta*arrival_successful + (1-zeta)*p_i_est[i_sel_idx]\n",
    "            p_i_est_avg[:, k] += p_i_est\n",
    "    \n",
    "        # Calculate max normalized throughput debt\n",
    "        x_max_norm += np.max(np.where(x_i > 0, x_i, 0) / (K*q_i))\n",
    "        #print(J_avg_g/(K*M))\n",
    "        \n",
    "    J_avg_exp /= (G*K*M)\n",
    "    x_max_norm /= G\n",
    "    p_i_est_avg /= G\n",
    "\n",
    "    return J_avg_exp, x_max_norm, p_i_est_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd982358-dc3a-41cc-9f07-2cecd585a58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Simulate the drift-plus-penalty policy\n",
    "\n",
    "Inputs:\n",
    "M : number of node\n",
    "K : time horizon\n",
    "alpha_i : per-node weight (M x 1)\n",
    "q_i : per-node throughput constraint (M x 1)\n",
    "p_i_k : per-node probability trace (M x K)\n",
    "p_est_init_i : per-node initial probability estimate (M x 1)\n",
    "V_prime : priority of throughput constraint in scheduling\n",
    "G : number of simulations (output will be averaged over G)\n",
    "K_opt : optimization horizon (how often the optimization is performed)\n",
    "zeta : exponential moving average estimator weight\n",
    "\n",
    "Outputs:\n",
    "J_avg_exp : expected weighted sum AoI\n",
    "x_max_norm : max normalized throughput debt\n",
    "p_i_est_avg : per-node estimated probability trace (M x K)\n",
    "\"\"\"\n",
    "\n",
    "def sim_drift_plus_penalty(M, K, alpha_i, q_i, p_i_k, p_est_init_i, V_prime, G, K_opt, zeta, exact=False):\n",
    "    J_avg_exp = 0\n",
    "    x_max_norm = 0\n",
    "    p_i_est_avg = np.zeros((M,K))\n",
    "    \n",
    "    # Repeat simulation\n",
    "    for z in range(G):\n",
    "        # Initialize transmission matrix that indiciates which node has an arrival in which slot\n",
    "        d_i_k = np.zeros((M,K))\n",
    "        \n",
    "        # Initialize AoI and throughput debt vectors\n",
    "        h_i = np.ones(M)\n",
    "        x_i = np.zeros(M)\n",
    "        x_i_opt = np.zeros(M)\n",
    "    \n",
    "        # Generate outcome matrix that indicates whether transmission is successful in each time slot, assuming it is the selected time slot\n",
    "        o_i_k = stats.bernoulli.rvs(p=p_i_k, size=(M,K), random_state=z+3000)\n",
    "\n",
    "        # DEBUG:\n",
    "        #J_avg_g = 0\n",
    "    \n",
    "        # Initialize estimates of p_i\n",
    "        p_i_est = np.copy(p_est_init_i)\n",
    "    \n",
    "        # For each optimization horizon\n",
    "        for opt_hor in range(int(K/K_opt)):\n",
    "            # Throughput requirements for optimization\n",
    "            tp_sum = np.sum(q_i/p_i_est)\n",
    "            \n",
    "            # Check whether q is a feasible set of minimum throughput requirements\n",
    "            q_i_opt = q_i\n",
    "            if tp_sum > 1.0:\n",
    "                # Best we can do is solve the optimization problem with lower throughput requirements\n",
    "                q_i_opt /= tp_sum\n",
    "                \n",
    "                #print(f\"DPP: TP Req Unfeasible {tp_sum}, opt no {opt_hor+1}\")\n",
    "            \n",
    "            # Repeated calculation\n",
    "            q_i_div_p_i = q_i_opt/p_i_est\n",
    "            \n",
    "            # Solve optimization\n",
    "            gamma_i = alpha_i*p_i_est/(M*q_i_opt**2)\n",
    "            gamma = gamma_test = np.max(gamma_i)\n",
    "            sqrt = np.sqrt(gamma_i/gamma_test)\n",
    "            mu_i = mu_i_test = q_i_div_p_i * np.where(sqrt > 1, sqrt, 1)\n",
    "            S = S_test = np.sum(mu_i_test)\n",
    "    \n",
    "            # Get close to the optimal value through successive division by 2 (This significantly speeds up optimization)\n",
    "            while S_test < 1.0:\n",
    "                gamma = gamma_test\n",
    "                mu_i = mu_i_test\n",
    "                S = S_test\n",
    "                \n",
    "                gamma_test /= 2.0\n",
    "                sqrt = np.sqrt(gamma_i/gamma_test)\n",
    "                mu_i_test = q_i_div_p_i * np.where(sqrt > 1, sqrt, 1)\n",
    "                S_test = np.sum(mu_i_test)\n",
    "\n",
    "            # More exact optimization starting from value from previous loop\n",
    "            step_size = 0.1\n",
    "            while S < 1.0:\n",
    "                S_prev = S\n",
    "                gamma -= step_size\n",
    "                sqrt = np.sqrt(gamma_i/gamma)\n",
    "                mu_i = q_i_div_p_i * np.where(sqrt > 1, sqrt, 1)\n",
    "                S = np.sum(mu_i)\n",
    "\n",
    "                # Adjust step size dynamically if it is too small\n",
    "                if np.abs(S-S_prev) < 0.001:\n",
    "                    step_size *= 2\n",
    "    \n",
    "            # Ensure that mu_i exactly add up to one\n",
    "            mu_i /= la.norm(mu_i, ord=1)\n",
    "            \n",
    "            # Loop over slots\n",
    "            for k in range(K_opt):\n",
    "                # Select node according to policy\n",
    "                W_prime_i = (0.5)*alpha_i/mu_i*h_i + V_prime*p_i_est*np.where(x_i_opt > 0, x_i_opt, 0)\n",
    "                i_sel_idx = np.argmax(W_prime_i)\n",
    "                \n",
    "                # Update transmission matrix based on whether transmission was successful or not\n",
    "                arrival_successful = o_i_k[i_sel_idx, k + opt_hor*K_opt]\n",
    "                d_i_k[i_sel_idx, k + opt_hor*K_opt] = arrival_successful\n",
    "    \n",
    "                # Calculate weighted sum AoI\n",
    "                J_avg_exp += np.sum(alpha_i * h_i)\n",
    "                #J_avg_g += np.sum(alpha_i * h_i)\n",
    "                \n",
    "                # Update AoI and throughput debt vectors\n",
    "                h_i += 1\n",
    "                if arrival_successful: # if transmission was successful\n",
    "                    h_i[i_sel_idx] = 1\n",
    "                x_i += q_i - d_i_k[:, k + opt_hor*K_opt]\n",
    "                x_i_opt += q_i_opt - d_i_k[:, k + opt_hor*K_opt]\n",
    "        \n",
    "                # Update estimate for the scheduled node\n",
    "                if exact:\n",
    "                    p_i_est = p_i_k[:, k + opt_hor*K_opt]\n",
    "                else:\n",
    "                    p_i_est[i_sel_idx] = zeta*arrival_successful + (1-zeta)*p_i_est[i_sel_idx]\n",
    "                p_i_est_avg[:, k + opt_hor*K_opt] += p_i_est\n",
    "    \n",
    "        # Calculate max normalized throughput debt\n",
    "        x_max_norm += np.max(np.where(x_i > 0, x_i, 0) / (K*q_i))\n",
    "        #print(J_avg_g/(K*M))\n",
    "        \n",
    "    J_avg_exp /= (G*K*M)\n",
    "    x_max_norm /= G\n",
    "    p_i_est_avg /= G\n",
    "\n",
    "    return J_avg_exp, x_max_norm, p_i_est_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ce61e35-b65f-438e-aeeb-eee507cc7c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Simulate the Whittle's index policy with throughput constraints\n",
    "\n",
    "Inputs:\n",
    "M : number of node\n",
    "K : time horizon\n",
    "alpha_i : per-node weight (M x 1)\n",
    "q_i : per-node throughput constraint (M x 1)\n",
    "p_i_k : per-node probability trace (M x K)\n",
    "p_est_init_i : per-node initial probability estimate (M x 1)\n",
    "G : number of simulations (output will be averaged over G)\n",
    "K_opt : optimization horizon (how often the optimization is performed)\n",
    "zeta : exponential moving average estimator weight\n",
    "\n",
    "Outputs:\n",
    "J_avg_exp : expected weighted sum AoI\n",
    "x_max_norm : max normalized throughput debt\n",
    "p_i_est_avg : per-node estimated probability trace (M x K)\n",
    "\"\"\"\n",
    "\n",
    "def sim_whittle_index_policy_with_tp_con(M, K, alpha_i, q_i, p_i_k, p_est_init_i, G, K_opt, zeta, exact=False):\n",
    "    J_avg_exp = 0\n",
    "    x_max_norm = 0\n",
    "    p_i_est_avg = np.zeros((M,K))\n",
    "    \n",
    "    # Repeat simulation\n",
    "    for z in range(G):\n",
    "        # Initialize transmission matrix that indiciates which node has an arrival in which slot\n",
    "        d_i_k = np.zeros((M,K))\n",
    "        \n",
    "        # Initialize AoI and throughput debt vectors\n",
    "        h_i = np.ones(M)\n",
    "        x_i = np.zeros(M)\n",
    "    \n",
    "        # Generate outcome matrix that indicates whether transmission is successful in each time slot, assuming it is the selected time slot\n",
    "        o_i_k = stats.bernoulli.rvs(p=p_i_k, size=(M,K), random_state=z+4000)\n",
    "    \n",
    "        # Initialize estimates of p_i\n",
    "        p_i_est = np.copy(p_est_init_i)\n",
    "    \n",
    "        # For each optimization horizon\n",
    "        for opt_hor in range(int(K/K_opt)):\n",
    "            # Throughput requirements for optimization\n",
    "            tp_sum = np.sum(q_i/p_i_est)\n",
    "            \n",
    "            # Check whether q is a feasible set of minimum throughput requirements\n",
    "            q_i_opt = q_i\n",
    "            if tp_sum > 1.0:\n",
    "                # If not, best we can do is solve the optimization problem with lower throughput requirements\n",
    "                q_i_opt /= tp_sum\n",
    "                #print(f\"WI: TP Req Unfeasible {tp_sum}, opt no {opt_hor+1}\")\n",
    "    \n",
    "            # Solve optimization\n",
    "            chi_i = alpha_i*p_i_est*((1/q_i_opt)**2 - (1/p_i_est - 1/2)**2)/2\n",
    "            C = C_test = np.max(chi_i)\n",
    "            phi_i_inv = phi_i_inv_test = p_i_est*np.sqrt(2*np.where(chi_i < C_test, chi_i, C_test) / (alpha_i*p_i_est) + (1/p_i_est - 1/2)**2)\n",
    "            S = S_test = np.sum(1/phi_i_inv_test)\n",
    "    \n",
    "            while S_test < 1.0:\n",
    "                C = C_test\n",
    "                phi_i_inv = phi_i_inv_test\n",
    "                S = S_test\n",
    "    \n",
    "                C_test /= 2.0\n",
    "                phi_i_inv_test = p_i_est*np.sqrt(2*np.where(chi_i < C_test, chi_i, C_test) / (alpha_i*p_i_est) + (1/p_i_est - 1/2)**2)\n",
    "                S_test = np.sum(1/phi_i_inv_test)\n",
    "            \n",
    "            # More exact optimization starting from value from previous loop\n",
    "            step_size = 0.1\n",
    "            while S < 1.0:\n",
    "                S_prev = S\n",
    "                C -= step_size\n",
    "                phi_i_inv = p_i_est*np.sqrt(2*np.where(chi_i < C, chi_i, C) / (alpha_i*p_i_est) + (1/p_i_est - 1/2)**2)\n",
    "                S = np.sum(1/phi_i_inv)\n",
    "                \n",
    "                # Adjust step size dynamically if it is too small\n",
    "                if np.abs(S-S_prev) < 0.001:\n",
    "                    step_size *= 2\n",
    "                \n",
    "            C_star = C\n",
    "            chi_i_star = np.where(chi_i < C_star, chi_i, C_star)\n",
    "            theta_i = C_star - chi_i_star\n",
    "            \n",
    "            # Loop over slots\n",
    "            for k in range(K_opt):\n",
    "                # Select node according to policy\n",
    "                C_i_h_i = 0.5*alpha_i*p_i_est*(h_i**2 + (2/p_i_est)*h_i - h_i) + theta_i\n",
    "                i_sel_idx = np.argmax(C_i_h_i)\n",
    "                \n",
    "                # Update transmission matrix based on whether transmission was successful or not\n",
    "                arrival_successful = o_i_k[i_sel_idx, k + opt_hor*K_opt]\n",
    "                d_i_k[i_sel_idx, k + opt_hor*K_opt] = arrival_successful\n",
    "    \n",
    "                # Calculate weighted sum AoI\n",
    "                J_avg_exp += np.sum(alpha_i * h_i)\n",
    "                \n",
    "                # Update AoI and throughput debt vectors\n",
    "                h_i += 1\n",
    "                if arrival_successful: # if transmission was successful\n",
    "                    h_i[i_sel_idx] = 1\n",
    "                x_i += q_i - d_i_k[:, k + opt_hor*K_opt]\n",
    "    \n",
    "                # Update estimate for the scheduled node\n",
    "                if exact:\n",
    "                    p_i_est = p_i_k[:, k + opt_hor*K_opt]\n",
    "                else:\n",
    "                    p_i_est[i_sel_idx] = zeta*arrival_successful + (1-zeta)*p_i_est[i_sel_idx]\n",
    "                p_i_est_avg[:, k + opt_hor*K_opt] += p_i_est\n",
    "    \n",
    "        # Calculate max normalized throughput debt\n",
    "        x_max_norm += np.max(np.where(x_i > 0, x_i, 0) / (K*q_i))\n",
    "        \n",
    "    J_avg_exp /= (G*K*M)\n",
    "    x_max_norm /= G\n",
    "    p_i_est_avg /= G\n",
    "\n",
    "    return J_avg_exp, x_max_norm, p_i_est_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af660398-58a7-44dc-b0cb-d74f0abaac79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Simulate the maximum weighted average policy\n",
    "\n",
    "Inputs:\n",
    "M : number of node\n",
    "K : time horizon\n",
    "alpha_i : per-node weight (M x 1)\n",
    "q_i : per-node throughput constraint (M x 1)\n",
    "p_i_k : per-node probability trace (M x K)\n",
    "G : number of simulations (output will be averaged over G)\n",
    "\n",
    "Outputs:\n",
    "J_avg_exp : expected weighted sum AoI\n",
    "x_max_norm : max normalized throughput debt\n",
    "\"\"\"\n",
    "\n",
    "def sim_max_weighted_average_policy(M, K, alpha_i, q_i, p_i_k, G):\n",
    "    J_avg_exp = 0\n",
    "    x_max_norm = 0\n",
    "\n",
    "    # Repeat simulation\n",
    "    for z in range(G):\n",
    "        # Initialize transmission matrix that indiciates which node has an arrival in which slot\n",
    "        d_i_k = np.zeros((M,K))\n",
    "        \n",
    "        # Initialize AoI and throughput debt vectors\n",
    "        h_i = np.ones(M)\n",
    "        x_i = np.zeros(M)\n",
    "    \n",
    "        # Generate outcome matrix that indicates whether transmission is successful in each time slot, assuming it is the selected time slot\n",
    "        o_i_k = stats.bernoulli.rvs(p=p_i_k, size=(M,K), random_state=z+5000)\n",
    "\n",
    "        # Loop over slots\n",
    "        for k in range(K):\n",
    "            # Select node according to policy\n",
    "            i_sel_idx = np.argmax(alpha_i * h_i)\n",
    "            \n",
    "            # Update transmission matrix based on whether transmission was successful or not\n",
    "            arrival_successful = o_i_k[i_sel_idx, k]\n",
    "            d_i_k[i_sel_idx, k] = arrival_successful\n",
    "    \n",
    "            # Calculate weighted sum AoI\n",
    "            J_avg_exp += np.sum(alpha_i * h_i)\n",
    "            \n",
    "            # Update AoI and throughput debt vectors\n",
    "            h_i += 1\n",
    "            if arrival_successful: # if transmission was successful\n",
    "                h_i[i_sel_idx] = 1\n",
    "            x_i += q_i - d_i_k[:, k]\n",
    "    \n",
    "        # Calculate max normalized throughput debt\n",
    "        x_max_norm += np.max(np.where(x_i > 0, x_i, 0) / (K*q_i))\n",
    "        #print(J_avg_g/(K*M))\n",
    "        \n",
    "    J_avg_exp /= (G*K*M)\n",
    "    x_max_norm /= G\n",
    "\n",
    "    return J_avg_exp, x_max_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "109977d6-6214-43d5-9c78-5df5bb096ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Simulate the Whittle's index policy without throughput constraints\n",
    "\n",
    "Inputs:\n",
    "M : number of nodes\n",
    "K : time horizon\n",
    "alpha_i : per-node weight (M x 1)\n",
    "q_i : per-node throughput constraint (M x 1)\n",
    "p_i_k : per-node probability trace (M x K)\n",
    "p_est_init_i : per-source initial probability estimate (M x 1)\n",
    "G : number of simulations (output will be averaged over G)\n",
    "zeta : exponential moving average estimator weight\n",
    "\n",
    "Outputs:\n",
    "J_avg_exp : expected weighted sum AoI\n",
    "x_max_norm : max normalized throughput debt\n",
    "p_i_est_avg : per-node estimated probability trace (M x K)\n",
    "\"\"\"\n",
    "\n",
    "def sim_whittle_index_policy_without_tp_con(M, K, alpha_i, q_i, p_i_k, p_est_init_i, G, zeta, exact=False):\n",
    "    J_avg_exp = 0\n",
    "    x_max_norm = 0\n",
    "    p_i_est_avg = np.zeros((M,K))\n",
    "    \n",
    "    # Repeat simulation\n",
    "    for z in range(G):\n",
    "        # Initialize transmission matrix that indiciates which node has an arrival in which slot\n",
    "        d_i_k = np.zeros((M,K))\n",
    "        \n",
    "        # Initialize AoI and throughput debt vectors\n",
    "        h_i = np.ones(M)\n",
    "        x_i = np.zeros(M)\n",
    "    \n",
    "        # Generate outcome matrix that indicates whether transmission is successful in each time slot, assuming it is the selected time slot\n",
    "        o_i_k = stats.bernoulli.rvs(p=p_i_k, size=(M,K), random_state=z+6000)\n",
    "    \n",
    "        # Initialize estimates of p_i\n",
    "        p_i_est = np.copy(p_est_init_i)\n",
    "        \n",
    "        # Loop over slots\n",
    "        for k in range(K):\n",
    "            # Select node according to policy\n",
    "            C_i_h_i = 0.5*alpha_i*p_i_est*(h_i**2 + (2/p_i_est)*h_i - h_i)\n",
    "            i_sel_idx = np.argmax(C_i_h_i)\n",
    "            \n",
    "            # Update transmission matrix based on whether transmission was successful or not\n",
    "            arrival_successful = o_i_k[i_sel_idx, k]\n",
    "            d_i_k[i_sel_idx, k] = arrival_successful\n",
    "    \n",
    "            # Calculate weighted sum AoI\n",
    "            J_avg_exp += np.sum(alpha_i * h_i)\n",
    "            \n",
    "            # Update AoI and throughput debt vectors\n",
    "            h_i += 1\n",
    "            if arrival_successful: # if transmission was successful\n",
    "                h_i[i_sel_idx] = 1\n",
    "            x_i += q_i - d_i_k[:, k]\n",
    "    \n",
    "            # Update estimate for the scheduled node\n",
    "            if exact:\n",
    "                p_i_est = p_i_k[:, k]\n",
    "            else:\n",
    "                p_i_est[i_sel_idx] = zeta*arrival_successful + (1-zeta)*p_i_est[i_sel_idx]\n",
    "            p_i_est_avg[:, k] += p_i_est\n",
    "    \n",
    "        # Calculate max normalized throughput debt\n",
    "        x_max_norm += np.max(np.where(x_i > 0, x_i, 0) / (K*q_i))\n",
    "        \n",
    "    J_avg_exp /= (G*K*M)\n",
    "    x_max_norm /= G\n",
    "    p_i_est_avg /= G\n",
    "\n",
    "    return J_avg_exp, x_max_norm, p_i_est_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "104f69d8-c8d1-4202-b1b4-a26d673a46bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Simulate the largest weighted debt first policy\n",
    "\n",
    "Inputs:\n",
    "M : number of nodes\n",
    "K : time horizon\n",
    "alpha_i : per-node weight (M x 1)\n",
    "q_i : per-node throughput constraint (M x 1)\n",
    "p_i_k : per-node probability trace (M x K)\n",
    "p_est_init_i : per-source initial probability estimate (M x 1)\n",
    "G : number of simulations (output will be averaged over G)\n",
    "zeta : exponential moving average estimator weight\n",
    "\n",
    "Outputs:\n",
    "J_avg_exp : expected weighted sum AoI\n",
    "x_max_norm : max normalized throughput debt\n",
    "p_i_est_avg : per-node estimated probability trace (M x K)\n",
    "\"\"\"\n",
    "\n",
    "def sim_largest_weighted_debt_first_policy(M, K, alpha_i, q_i, p_i_k, p_est_init_i, G, zeta, exact=False):\n",
    "    J_avg_exp = 0\n",
    "    x_max_norm = 0\n",
    "    p_i_est_avg = np.zeros((M,K))\n",
    "    \n",
    "    # Repeat simulation\n",
    "    for z in range(G):\n",
    "        # Initialize transmission matrix that indiciates which node has an arrival in which slot\n",
    "        d_i_k = np.zeros((M,K))\n",
    "        \n",
    "        # Initialize AoI and throughput debt vectors\n",
    "        h_i = np.ones(M)\n",
    "        x_i = np.zeros(M)\n",
    "    \n",
    "        # Generate outcome matrix that indicates whether transmission is successful in each time slot, assuming it is the selected time slot\n",
    "        o_i_k = stats.bernoulli.rvs(p=p_i_k, size=(M,K), random_state=z+7000)\n",
    "    \n",
    "        # Initialize estimates of p_i\n",
    "        p_i_est = np.copy(p_est_init_i)\n",
    "        \n",
    "        # Loop over slots\n",
    "        for k in range(K):\n",
    "            # Select node according to policy\n",
    "            i_sel_idx = np.argmax(x_i/p_i_est)\n",
    "            \n",
    "            # Update transmission matrix based on whether transmission was successful or not\n",
    "            arrival_successful = o_i_k[i_sel_idx, k]\n",
    "            d_i_k[i_sel_idx, k] = arrival_successful\n",
    "    \n",
    "            # Calculate weighted sum AoI\n",
    "            J_avg_exp += np.sum(alpha_i * h_i)\n",
    "            \n",
    "            # Update AoI and throughput debt vectors\n",
    "            h_i += 1\n",
    "            if arrival_successful: # if transmission was successful\n",
    "                h_i[i_sel_idx] = 1\n",
    "            x_i += q_i - d_i_k[:, k]\n",
    "    \n",
    "            # Update estimate for the scheduled node\n",
    "            if exact:\n",
    "                p_i_est = p_i_k[:, k]\n",
    "            else:\n",
    "                p_i_est[i_sel_idx] = zeta*arrival_successful + (1-zeta)*p_i_est[i_sel_idx]\n",
    "            p_i_est_avg[:, k] += p_i_est\n",
    "    \n",
    "        # Calculate max normalized throughput debt\n",
    "        x_max_norm += np.max(np.where(x_i > 0, x_i, 0) / (K*q_i))\n",
    "        \n",
    "    J_avg_exp /= (G*K*M)\n",
    "    x_max_norm /= G\n",
    "    p_i_est_avg /= G\n",
    "\n",
    "    return J_avg_exp, x_max_norm, p_i_est_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34683e4c-2c2a-4b44-adca-6df9d65054df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting sims for volatility 0\n",
      "starting sims for 5 nodes\n",
      "4.8704199200006695\n",
      "finished iteration 1 of 10\n"
     ]
    }
   ],
   "source": [
    "H = 10\n",
    "G = 10\n",
    "\n",
    "# Constant parameters\n",
    "epsilon = 0.9  # Must be [0, 1)\n",
    "K_opt = 500\n",
    "zeta = 0.05\n",
    "\n",
    "# Varying parameters\n",
    "volatilities = np.array([0])#np.array([0, 0.005, 0.01, 0.02])\n",
    "M_values = np.arange(5, 31, 5)\n",
    "K_values = M_values * 10**4\n",
    "V_values = V_prime_values = M_values**2\n",
    "\n",
    "J_avg_exp_values = np.zeros((len(volatilities),6))\n",
    "x_max_norm_values = np.zeros((len(volatilities),6))\n",
    "\n",
    "# Run sims across number of nodes\n",
    "for vol in range(len(volatilities)):\n",
    "    volatility_param = volatilities[vol]\n",
    "    print(f\"starting sims for volatility {volatility_param}\")\n",
    "    for j in range(6):\n",
    "        M = M_values[j]\n",
    "        K = K_values[j]\n",
    "        V = V_values[j]\n",
    "        V_prime = V_prime_values[j]\n",
    "    \n",
    "        # Set per-node parameters\n",
    "        i = np.arange(start=1, stop=M+1)\n",
    "        alpha_i = (M + 1 - i)/M\n",
    "        p_i = i/M # Initial values for both the probability traces and the probability estimates\n",
    "        # (Assumption that we are making is that the scheduler knows this information about the channel. This is to ensure consistency with the Kadota paper)\n",
    "        q_i = epsilon*p_i/M\n",
    "    \n",
    "        print(f\"starting sims for {M} nodes\")\n",
    "        \n",
    "        # Run sims H*G times\n",
    "        for z in range(H):\n",
    "            # Generate probability traces\n",
    "            if volatility_param != 0:\n",
    "                p_i_k = generate_prob_traces(M, K, p_i, z+100*vol, volatility_param)\n",
    "            else:\n",
    "                p_i_k = np.repeat(np.reshape(p_i, (M,1)), K, axis=1)\n",
    "\n",
    "            if policy == \"r_star\":\n",
    "                J_avg_exp, x_max_norm, _ = sim_opt_stat_random_policy(M, K, alpha_i, q_i, p_i_k, p_i, G, K_opt, zeta, exact=False)\n",
    "            elif policy == \"mw\":\n",
    "                J_avg_exp, x_max_norm, _ = sim_max_weight_policy(M, K, alpha_i, q_i, p_i_k, p_i, V, G, zeta, exact=False)\n",
    "            elif policy == \"dpp\":\n",
    "                J_avg_exp, x_max_norm, _ = sim_drift_plus_penalty(M, K, alpha_i, q_i, p_i_k, p_i, V_prime, G, K_opt, zeta, exact=False)\n",
    "            elif policy == \"wi\":\n",
    "                J_avg_exp, x_max_norm, _ = sim_whittle_index_policy_with_tp_con(M, K, alpha_i, q_i, p_i_k, p_i, G, K_opt, zeta, exact=False)\n",
    "            elif policy == \"mwa\":\n",
    "                J_avg_exp, x_max_norm, _ = sim_max_weighted_average_policy(M, K, alpha_i, q_i, p_i_k, G)\n",
    "            elif policy == \"wp\":\n",
    "                J_avg_exp, x_max_norm, _ = sim_whittle_index_policy_without_tp_con(M, K, alpha_i, q_i, p_i_k, p_i, G, zeta, exact=False)\n",
    "            elif policy == \"ld\":\n",
    "                J_avg_exp, x_max_norm, _ = sim_largest_weighted_debt_first_policy(M, K, alpha_i, q_i, p_i_k, p_i, G, zeta, exact=False)\n",
    "            print(J_avg_exp)\n",
    "    \n",
    "            J_avg_exp_values[vol,j] += J_avg_exp\n",
    "            x_max_norm_values[vol,j] += x_max_norm\n",
    "    \n",
    "            print(f\"finished iteration {z+1} of {H}\")\n",
    "        \n",
    "    J_avg_exp_values[vol,:] /= H\n",
    "    x_max_norm_values[vol,:] /= H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c30895-6756-434b-9447-02d4217ba91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(policy+\"J_avg_exp_values\", J_avg_exp_values)\n",
    "np.save(policy+\"x_max_norm_values\", x_max_norm_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6adae51-88f5-4831-b6a0-74ba63f805c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(M_values, J_avg_exp_values[0,:], color='y', linestyle='dashed', label='vp=0', marker=\"x\")\n",
    "plt.plot(M_values, J_avg_exp_values[1,:], color='r', linestyle='dashed', label='vp=0.005', marker=\"v\")\n",
    "plt.plot(M_values, J_avg_exp_values[2,:], color='b', linestyle='dashed', label='vp=0.01', marker=\"o\")\n",
    "plt.plot(M_values, J_avg_exp_values[3,:], color='c', linestyle='dashed', label='vp=0.02', marker=\"<\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Number of nodes, M\")\n",
    "plt.ylabel(\"Expected Weighted Sum AoI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e12b5c2-d98f-4f89-bf70-3e66ed9b0c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(M_values, x_max_norm_values[0,:], color='y', linestyle='dashed', label='vp=0', marker=\"x\")\n",
    "plt.plot(M_values, x_max_norm_values[1,:], color='r', linestyle='dashed', label='vp=0.005', marker=\"v\")\n",
    "plt.plot(M_values, x_max_norm_values[2,:], color='b', linestyle='dashed', label='vp=0.01', marker=\"o\")\n",
    "plt.plot(M_values, x_max_norm_values[3,:], color='c', linestyle='dashed', label='vp=0.02', marker=\"<\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Number of nodes, M\")\n",
    "plt.ylabel(\"Expected Weighted Sum AoI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe82c7f-fc0f-4bb6-9dbe-7e7839b1f998",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure()\n",
    "#plt.plot(M_values, r_star_J_avg_exp_values, color='r', linestyle='dashed', label='R*', marker=\"v\")\n",
    "#plt.plot(M_values, mw_J_avg_exp_values, color='b', linestyle='dashed', label='MW', marker=\"o\")\n",
    "#plt.plot(M_values, dpp_J_avg_exp_values, color='c', linestyle='dashed', label='DPP', marker=\"<\")\n",
    "#plt.plot(M_values, wi_J_avg_exp_values, color='k', linestyle='dashed', label='WI w/ TP', marker=\"^\")\n",
    "#plt.plot(M_values, mwa_J_avg_exp_values, color='y', linestyle='dashed', label='MWA', marker=\"d\")\n",
    "#plt.plot(M_values, wp_J_avg_exp_values, color='g', linestyle='dashed', label='WI w/o TP', marker=\"x\")\n",
    "#plt.plot(M_values, ld_J_avg_exp_values, color='m', linestyle='dashed', label='LD', marker=\"+\")\n",
    "#plt.legend()\n",
    "#plt.xlabel(\"Number of nodes, M\")\n",
    "#plt.ylabel(\"Expected Weighted Sum AoI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2e554e-83fc-4d3e-b16d-574c283f6c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure()\n",
    "#plt.plot(M_values, r_star_x_max_norm_values, color='r', linestyle='dashed', label='R*', marker=\"v\")\n",
    "#plt.plot(M_values, mw_x_max_norm_values, color='b', linestyle='dashed', label='MW', marker=\"o\")\n",
    "#plt.plot(M_values, dpp_x_max_norm_values, color='c', linestyle='dashed', label='DPP', marker=\"<\")\n",
    "#plt.plot(M_values, wi_x_max_norm_values, color='k', linestyle='dashed', label='WI w/ TP', marker=\"^\")\n",
    "#plt.plot(M_values, mwa_x_max_norm_values, color='y', linestyle='dashed', label='MWA', marker=\"d\")\n",
    "#plt.plot(M_values, wp_x_max_norm_values, color='g', linestyle='dashed', label='WI w/o TP', marker=\"x\")\n",
    "#plt.plot(M_values, ld_x_max_norm_values, color='m', linestyle='dashed', label='LD', marker=\"+\")\n",
    "#plt.legend()\n",
    "#plt.xlabel(\"Number of nodes, M\")\n",
    "#plt.ylabel(\"Max Normalized Throughput Debt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff44198d-c1f3-4313-9a88-922a318149e1",
   "metadata": {},
   "source": [
    "LD, MW, and DPP are the only policies that explicitly consider throughput debt. Both MW and DPP also consider AoI. However, with MW, the weight is quadratic with respect to AoI, while with DPP, the weight is linear with respect to AoI. LD does not consider AoI at all. Hence, it could be concluded that LD and DPP put too much importance on throughput debt, and not enough on AoI. While performance under static network conditions is comparable between MW and DPP, the advantage of MW is revealed under stochastic, unknown network conditions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
